#!/usr/bin/env python3
"""
ç°¡åŒ–ç‰ˆçš„åœæ£‹æ£‹é¢¨æª¢æ¸¬ - ä¸ä¾è³´ C++ ç·¨è­¯
ç›´æ¥ä½¿ç”¨ Python å’Œ PyTorch é€²è¡Œé–‹ç™¼

å®Œæ•´åŠŸèƒ½:
1. è¨“ç·´è³‡æ–™è¼‰å…¥èˆ‡ç©å®¶åˆ†çµ„
2. Triplet Loss è¨“ç·´
3. Query/Candidate æ¨ç†
4. ç”Ÿæˆ submission.csv
"""

import os
import glob
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from sgfmill import sgf
from pathlib import Path
from collections import defaultdict
import pandas as pd
from tqdm import tqdm
import argparse

class SimpleGoEncoder(nn.Module):
    """ç°¡å–®çš„åœæ£‹æ£‹é¢¨ç·¨ç¢¼å™¨"""
    
    def __init__(self, board_size=19, n_frames=10, embedding_dim=128):
        super().__init__()
        self.board_size = board_size
        self.n_frames = n_frames
        self.embedding_dim = embedding_dim
        
        # CNN ç‰¹å¾µæå–
        self.conv_layers = nn.Sequential(
            nn.Conv2d(n_frames * 3, 64, kernel_size=3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(),
            nn.Conv2d(64, 128, kernel_size=3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(),
            nn.MaxPool2d(2),
            nn.Conv2d(128, 256, kernel_size=3, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(),
            nn.Conv2d(256, 512, kernel_size=3, padding=1),
            nn.BatchNorm2d(512),
            nn.ReLU(),
            nn.AdaptiveAvgPool2d(1)
        )
        
        # Embedding layers
        self.fc = nn.Sequential(
            nn.Linear(512, 256),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(256, embedding_dim)
        )
    
    def forward(self, x):
        x = self.conv_layers(x)
        x = x.view(x.size(0), -1)
        x = self.fc(x)
        # L2 normalize for better similarity computation
        x = F.normalize(x, p=2, dim=1)
        return x


def load_sgf_file(filepath):
    """è¼‰å…¥å–®å€‹ SGF æª”æ¡ˆä¸¦è§£æ"""
    try:
        with open(filepath, 'rb') as f:
            game = sgf.Sgf_game.from_bytes(f.read())
        
        root = game.get_root()
        player_black = root.get('PB') if root.has_property('PB') else 'Unknown'
        player_white = root.get('PW') if root.has_property('PW') else 'Unknown'
        
        # ç²å–æ£‹è­œ
        moves = []
        node = root
        while node:
            children = node
            node = children[0] if children else None
            if node:
                move = node.get_move()
                if move[1]:  # å¦‚æœæœ‰è½å­
                    color, (row, col) = move
                    moves.append((color, row, col))
        
        return {
            'black': player_black,
            'white': player_white,
            'moves': moves,
            'filepath': filepath
        }
    except Exception as e:
        print(f"Error loading {filepath}: {e}")
        return None


def load_multi_game_sgf(filepath):
    """è¼‰å…¥åŒ…å«å¤šå ´éŠæˆ²çš„ SGF æª”æ¡ˆ (ç”¨æ–¼ query/candidate set)"""
    try:
        with open(filepath, 'rb') as f:
            content = f.read()
        
        # sgfmill ä¸ç›´æ¥æ”¯æ´å¤šéŠæˆ²æª”æ¡ˆï¼Œéœ€è¦æ‰‹å‹•åˆ†å‰²
        # ç°¡å–®æ–¹æ³•ï¼šæŒ‰ "(;" åˆ†å‰²ä¸¦é€å€‹è§£æ
        games = []
        game_strings = content.split(b'\n\n')  # å‡è¨­éŠæˆ²é–“æœ‰ç©ºè¡Œ
        
        for game_str in game_strings:
            if not game_str.strip() or not game_str.startswith(b'('):
                continue
            try:
                game = sgf.Sgf_game.from_bytes(game_str)
                root = game.get_root()
                
                moves = []
                node = root
                while node:
                    children = node
                    node = children[0] if children else None
                    if node:
                        move = node.get_move()
                        if move[1]:
                            color, (row, col) = move
                            moves.append((color, row, col))
                
                if moves:  # åªä¿ç•™æœ‰æ£‹æ­¥çš„éŠæˆ²
                    games.append({'moves': moves})
            except:
                continue
        
        return games
    except Exception as e:
        print(f"Error loading multi-game SGF {filepath}: {e}")
        return []


def sgf_to_features(moves, n_frames=10, board_size=19, random_start=True):
    """å°‡ SGF æ£‹æ­¥è½‰æ›ç‚ºç¥ç¶“ç¶²è·¯è¼¸å…¥ç‰¹å¾µ
    
    è¼¸å…¥æ ¼å¼: (n_frames*3, 19, 19)
    3 å€‹é€šé“: [é»‘å­ä½ç½®, ç™½å­ä½ç½®, ç•¶å‰ç©å®¶]
    """
    if len(moves) < n_frames:
        return None
    
    # é¸æ“‡é–‹å§‹ä½ç½®
    if random_start:
        start_idx = np.random.randint(0, max(1, len(moves) - n_frames + 1))
    else:
        start_idx = 0
    
    features = np.zeros((n_frames, 3, board_size, board_size), dtype=np.float32)
    board_black = np.zeros((board_size, board_size))
    board_white = np.zeros((board_size, board_size))
    
    for i, idx in enumerate(range(start_idx, min(start_idx + n_frames, len(moves)))):
        color, row, col = moves[idx]
        
        if color == 'b':
            board_black[row, col] = 1
            features[i, 0, :, :] = board_black.copy()
            features[i, 1, :, :] = board_white.copy()
            features[i, 2, :, :] = 1  # é»‘æ–¹å›åˆ
        else:
            board_white[row, col] = 1
            features[i, 0, :, :] = board_black.copy()
            features[i, 1, :, :] = board_white.copy()
            features[i, 2, :, :] = 0  # ç™½æ–¹å›åˆ
    
    return features.reshape(-1, board_size, board_size)  # (n_frames*3, 19, 19)


class GoStyleDataset(Dataset):
    """åœæ£‹é¢¨æ ¼è³‡æ–™é›† - ç”¨æ–¼è¨“ç·´"""
    
    def __init__(self, player_games, n_frames=10):
        """
        Args:
            player_games: dict {player_id: [list of game dicts with 'moves']}
        """
        self.player_games = player_games
        self.player_ids = list(player_games.keys())
        self.n_frames = n_frames
        
        # ç‚ºæ¯å€‹ç©å®¶å»ºç«‹éŠæˆ²ç´¢å¼•
        self.samples = []
        for player_id in self.player_ids:
            games = player_games[player_id]
            for game in games:
                if len(game['moves']) >= n_frames:
                    self.samples.append((player_id, game))
    
    def __len__(self):
        return len(self.samples)
    
    def __getitem__(self, idx):
        player_id, game = self.samples[idx]
        features = sgf_to_features(game['moves'], self.n_frames, random_start=True)
        
        if features is None:
            # Fallback: å›å‚³é›¶å‘é‡
            features = np.zeros((self.n_frames * 3, 19, 19), dtype=np.float32)
        
        return torch.FloatTensor(features), player_id


def collate_triplet_fn(batch):
    """è‡ªå®šç¾© collate function ç”¨æ–¼ç”Ÿæˆ triplet"""
    # æŒ‰ç©å®¶åˆ†çµ„
    player_samples = defaultdict(list)
    for features, player_id in batch:
        player_samples[player_id].append(features)
    
    # ç”Ÿæˆ triplets
    anchors, positives, negatives = [], [], []
    player_ids = list(player_samples.keys())
    
    if len(player_ids) < 2:
        # ä¸è¶³ä»¥å½¢æˆ tripletï¼Œå›å‚³ç©º
        return None
    
    for player_id in player_ids:
        if len(player_samples[player_id]) < 2:
            continue
        
        # Anchor å’Œ Positive ä¾†è‡ªåŒä¸€ç©å®¶
        anchor = player_samples[player_id][0]
        positive = player_samples[player_id][1] if len(player_samples[player_id]) > 1 else player_samples[player_id][0]
        
        # Negative ä¾†è‡ªä¸åŒç©å®¶
        other_players = [p for p in player_ids if p != player_id]
        if other_players:
            neg_player = np.random.choice(other_players)
            negative = player_samples[neg_player][0]
            
            anchors.append(anchor)
            positives.append(positive)
            negatives.append(negative)
    
    if not anchors:
        return None
    
    return (
        torch.stack(anchors),
        torch.stack(positives),
        torch.stack(negatives)
    )


class StyleDetectionSystem:
    """å®Œæ•´çš„æ£‹é¢¨æª¢æ¸¬ç³»çµ±"""
    
    def __init__(self, n_frames=10, embedding_dim=128, device='cuda'):
        self.n_frames = n_frames
        self.embedding_dim = embedding_dim
        self.device = torch.device(device if torch.cuda.is_available() else 'cpu')
        
        self.model = SimpleGoEncoder(
            n_frames=n_frames, 
            embedding_dim=embedding_dim
        ).to(self.device)
        
        print(f"ğŸ¯ æ¨¡å‹åƒæ•¸æ•¸é‡: {sum(p.numel() for p in self.model.parameters()):,}")
        print(f"ğŸ–¥ï¸  ä½¿ç”¨è¨­å‚™: {self.device}")
    
    def load_train_data(self, train_dir='train_set'):
        """è¼‰å…¥è¨“ç·´è³‡æ–™ä¸¦æŒ‰ç©å®¶åˆ†çµ„"""
        print(f"\nğŸ“‚ è¼‰å…¥è¨“ç·´è³‡æ–™: {train_dir}")
        
        sgf_files = sorted(glob.glob(f"{train_dir}/*.sgf"))
        print(f"   æ‰¾åˆ° {len(sgf_files)} å€‹ SGF æª”æ¡ˆ")
        
        # æŒ‰ç©å®¶åç¨±åˆ†çµ„
        player_games = defaultdict(list)
        
        for filepath in tqdm(sgf_files, desc="è®€å– SGF"):
            game_data = load_sgf_file(filepath)
            if game_data and len(game_data['moves']) >= self.n_frames:
                # ä½¿ç”¨é»‘æ–¹ç©å®¶ä½œç‚ºä¸»è¦ ID
                player_id = game_data['black']
                player_games[player_id].append(game_data)
        
        print(f"   å…±æœ‰ {len(player_games)} å€‹ä¸åŒç©å®¶")
        print(f"   å¹³å‡æ¯äºº {np.mean([len(games) for games in player_games.values()]):.1f} å ´éŠæˆ²")
        
        return player_games
    
    def train(self, player_games, epochs=50, batch_size=32, lr=0.001, save_path='model_best.pth'):
        """è¨“ç·´æ¨¡å‹ä½¿ç”¨ Triplet Loss"""
        print(f"\nğŸš€ é–‹å§‹è¨“ç·´...")
        
        dataset = GoStyleDataset(player_games, n_frames=self.n_frames)
        dataloader = DataLoader(
            dataset, 
            batch_size=batch_size, 
            shuffle=True, 
            collate_fn=collate_triplet_fn,
            num_workers=0
        )
        
        optimizer = torch.optim.Adam(self.model.parameters(), lr=lr)
        triplet_loss_fn = nn.TripletMarginLoss(margin=1.0)
        
        best_loss = float('inf')
        
        for epoch in range(epochs):
            self.model.train()
            epoch_loss = 0
            valid_batches = 0
            
            pbar = tqdm(dataloader, desc=f"Epoch {epoch+1}/{epochs}")
            for batch in pbar:
                if batch is None:
                    continue
                
                anchors, positives, negatives = batch
                anchors = anchors.to(self.device)
                positives = positives.to(self.device)
                negatives = negatives.to(self.device)
                
                # Forward pass
                anchor_emb = self.model(anchors)
                positive_emb = self.model(positives)
                negative_emb = self.model(negatives)
                
                # Compute loss
                loss = triplet_loss_fn(anchor_emb, positive_emb, negative_emb)
                
                # Backward pass
                optimizer.zero_grad()
                loss.backward()
                optimizer.step()
                
                epoch_loss += loss.item()
                valid_batches += 1
                
                pbar.set_postfix({'loss': f'{loss.item():.4f}'})
            
            if valid_batches > 0:
                avg_loss = epoch_loss / valid_batches
                print(f"Epoch {epoch+1}: Avg Loss = {avg_loss:.4f}")
                
                # å„²å­˜æœ€ä½³æ¨¡å‹
                if avg_loss < best_loss:
                    best_loss = avg_loss
                    torch.save(self.model.state_dict(), save_path)
                    print(f"âœ“ å„²å­˜æœ€ä½³æ¨¡å‹: {save_path}")
        
        print(f"\nâœ… è¨“ç·´å®Œæˆï¼æœ€ä½³ Loss: {best_loss:.4f}")
    
    def load_model(self, model_path):
        """è¼‰å…¥è¨“ç·´å¥½çš„æ¨¡å‹"""
        print(f"\nğŸ“¥ è¼‰å…¥æ¨¡å‹: {model_path}")
        self.model.load_state_dict(torch.load(model_path, map_location=self.device))
        self.model.eval()
        print("âœ“ æ¨¡å‹è¼‰å…¥å®Œæˆ")
    
    def extract_embedding(self, moves, num_samples=3):
        """å¾ä¸€å ´æˆ–å¤šå ´éŠæˆ²æå– embedding"""
        self.model.eval()
        embeddings = []
        
        with torch.no_grad():
            for _ in range(num_samples):
                features = sgf_to_features(moves, self.n_frames, random_start=True)
                if features is not None:
                    features = torch.FloatTensor(features).unsqueeze(0).to(self.device)
                    embedding = self.model(features)
                    embeddings.append(embedding.cpu())
        
        if embeddings:
            # å¹³å‡å¤šæ¬¡æ¡æ¨£
            avg_embedding = torch.mean(torch.cat(embeddings, dim=0), dim=0)
            return avg_embedding
        return None
    
    def extract_player_embedding(self, games, max_games=9):
        """å¾å¤šå ´éŠæˆ²æå–ç©å®¶çš„å¹³å‡ embedding"""
        embeddings = []
        
        for game in games[:max_games]:
            if 'moves' in game:
                emb = self.extract_embedding(game['moves'], num_samples=1)
                if emb is not None:
                    embeddings.append(emb)
        
        if embeddings:
            return torch.mean(torch.stack(embeddings), dim=0)
        return None
    
    def inference_on_test_set(self, query_dir='test_set/query_set', 
                               cand_dir='test_set/cand_set',
                               output_file='submission.csv'):
        """å°æ¸¬è©¦é›†é€²è¡Œæ¨ç†ä¸¦ç”Ÿæˆæäº¤æª”æ¡ˆ"""
        print(f"\nğŸ” é–‹å§‹æ¨ç†...")
        
        # è¼‰å…¥ Query Set
        print(f"\nğŸ“‚ è¼‰å…¥ Query Set: {query_dir}")
        query_files = sorted(glob.glob(f"{query_dir}/player*.sgf"))
        print(f"   æ‰¾åˆ° {len(query_files)} å€‹ query æª”æ¡ˆ")
        
        query_embeddings = {}
        for filepath in tqdm(query_files, desc="Query embedding"):
            player_num = int(Path(filepath).stem.replace('player', ''))
            games = load_multi_game_sgf(filepath)
            
            if games:
                embedding = self.extract_player_embedding(games, max_games=9)
                if embedding is not None:
                    query_embeddings[player_num] = embedding
        
        print(f"   æˆåŠŸæå– {len(query_embeddings)} å€‹ query embeddings")
        
        # è¼‰å…¥ Candidate Set
        print(f"\nï¿½ è¼‰å…¥ Candidate Set: {cand_dir}")
        cand_files = sorted(glob.glob(f"{cand_dir}/player*.sgf"))
        print(f"   æ‰¾åˆ° {len(cand_files)} å€‹ candidate æª”æ¡ˆ")
        
        cand_embeddings = {}
        for filepath in tqdm(cand_files, desc="Candidate embedding"):
            player_num = int(Path(filepath).stem.replace('player', ''))
            games = load_multi_game_sgf(filepath)
            
            if games:
                embedding = self.extract_player_embedding(games, max_games=9)
                if embedding is not None:
                    cand_embeddings[player_num] = embedding
        
        print(f"   æˆåŠŸæå– {len(cand_embeddings)} å€‹ candidate embeddings")
        
        # è¨ˆç®—ç›¸ä¼¼åº¦ä¸¦é…å°
        print(f"\nğŸ¯ è¨ˆç®—ç›¸ä¼¼åº¦...")
        predictions = {}
        
        for query_id, query_emb in tqdm(query_embeddings.items(), desc="é…å°"):
            best_cand_id = None
            best_similarity = -1
            
            for cand_id, cand_emb in cand_embeddings.items():
                # Cosine similarity (å› ç‚º embedding å·²ç¶“ normalized)
                similarity = torch.dot(query_emb, cand_emb).item()
                
                if similarity > best_similarity:
                    best_similarity = similarity
                    best_cand_id = cand_id
            
            predictions[query_id] = best_cand_id
        
        # ç”Ÿæˆ submission.csv
        print(f"\nğŸ’¾ ç”Ÿæˆæäº¤æª”æ¡ˆ: {output_file}")
        df = pd.DataFrame({
            'id': sorted(predictions.keys()),
            'label': [predictions[k] for k in sorted(predictions.keys())]
        })
        df.to_csv(output_file, index=False)
        print(f"âœ“ å·²å„²å­˜ {len(df)} ç­†é æ¸¬çµæœ")
        print(f"\nå‰ 10 ç­†é æ¸¬:")
        print(df.head(10))


def main():
    """ä¸»ç¨‹å¼"""
    parser = argparse.ArgumentParser(description='åœæ£‹æ£‹é¢¨æª¢æ¸¬ç³»çµ±')
    parser.add_argument('--mode', type=str, default='train', choices=['train', 'inference', 'full'],
                       help='é‹è¡Œæ¨¡å¼: train/inference/full')
    parser.add_argument('--train_dir', type=str, default='train_set', help='è¨“ç·´è³‡æ–™ç›®éŒ„')
    parser.add_argument('--query_dir', type=str, default='test_set/query_set', help='Query è³‡æ–™ç›®éŒ„')
    parser.add_argument('--cand_dir', type=str, default='test_set/cand_set', help='Candidate è³‡æ–™ç›®éŒ„')
    parser.add_argument('--model_path', type=str, default='model_best.pth', help='æ¨¡å‹å„²å­˜è·¯å¾‘')
    parser.add_argument('--output', type=str, default='submission.csv', help='æäº¤æª”æ¡ˆè·¯å¾‘')
    parser.add_argument('--epochs', type=int, default=50, help='è¨“ç·´è¼ªæ•¸')
    parser.add_argument('--batch_size', type=int, default=32, help='Batch size')
    parser.add_argument('--lr', type=float, default=0.001, help='å­¸ç¿’ç‡')
    parser.add_argument('--n_frames', type=int, default=10, help='ä½¿ç”¨çš„æ­·å² frames æ•¸é‡')
    parser.add_argument('--embedding_dim', type=int, default=128, help='Embedding ç¶­åº¦')
    
    args = parser.parse_args()
    
    print("=" * 60)
    print("ğŸ” åœæ£‹æ£‹é¢¨æª¢æ¸¬ç³»çµ±")
    print("=" * 60)
    
    # åˆå§‹åŒ–ç³»çµ±
    system = StyleDetectionSystem(
        n_frames=args.n_frames,
        embedding_dim=args.embedding_dim
    )
    
    if args.mode in ['train', 'full']:
        # è¨“ç·´æ¨¡å¼
        player_games = system.load_train_data(args.train_dir)
        system.train(
            player_games,
            epochs=args.epochs,
            batch_size=args.batch_size,
            lr=args.lr,
            save_path=args.model_path
        )
    
    if args.mode in ['inference', 'full']:
        # æ¨ç†æ¨¡å¼
        if args.mode == 'inference':
            system.load_model(args.model_path)
        
        system.inference_on_test_set(
            query_dir=args.query_dir,
            cand_dir=args.cand_dir,
            output_file=args.output
        )
    
    print("\n" + "=" * 60)
    print("âœ… å®Œæˆï¼")
    print("=" * 60)


if __name__ == "__main__":
    main()
